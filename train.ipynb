{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwhKOQ9gTpNf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_mapping import ID_TO_NAME, NAME_TO_ID, ID_TO_NAME_MAPPING\n",
    "\n",
    "NUM_CLASSES = len(ID_TO_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "CLASSIFICATION_DATASET_PATH = \"data/classification_dataset\"\n",
    "WEIGHTS_PATH = None #r\"checkpoints\\ckpt_epoch_006.pt\"\n",
    "LOAD_WEIGHTS = True  # set to False if you want to train from scratch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 1e-3\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_EPOCHS = 100\n",
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All class directories are present.\n"
     ]
    }
   ],
   "source": [
    "def check_class_dirs(base_path: str):\n",
    "    \"\"\"\n",
    "    For each class in ID_TO_NAME_MAPPING, verify if a directory named\n",
    "    after the class exists under base_path. If not, print it.\n",
    "    \"\"\"\n",
    "    missing = []\n",
    "    for class_id, (name, _) in ID_TO_NAME_MAPPING.items():\n",
    "        # Sanitize or normalize name if needed (e.g., replace spaces)\n",
    "        dir_name = \"class_\" + name.lower().replace(\" \",\"_\")\n",
    "        dir_path = os.path.join(base_path, dir_name)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            missing.append([dir_name,class_id])\n",
    "\n",
    "    if missing:\n",
    "        print(\"The following class directories are missing:\")\n",
    "        for name in missing:\n",
    "            print(f\" - {name}\")\n",
    "    else:\n",
    "        print(\"All class directories are present.\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    base_folder = \"classifier_data\"\n",
    "    check_class_dirs(base_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropWeedDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.root = []\n",
    "        for folder in os.listdir(image_dir):\n",
    "            folder_path = os.path.join(image_dir, folder)\n",
    "            for file in os.listdir(folder_path):\n",
    "                self.root.append(\n",
    "                    (folder[6:].replace(\"_\", \" \"), os.path.join(folder_path, file))\n",
    "                )\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.root)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label, image_path = self.root[idx]\n",
    "        label_id = NAME_TO_ID[label.lower()]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.25]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73824\n",
      "torch.Size([3, 256, 256])\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "dataset = CropWeedDataset(image_dir=CLASSIFICATION_DATASET_PATH, transform=transform)  \n",
    "print(len(dataset))  \n",
    "\n",
    "sample = dataset[random.randint(3, len(dataset))]\n",
    "print(sample[0].shape)\n",
    "print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import models\n",
    "from classification_models.MobileNet import MobileNetV2\n",
    "from classification_models.ResNet18 import ResNet18\n",
    "from classification_models.ShuffleNet import ShuffleNet\n",
    "from classification_models.ShuffleNet_SE import ShuffleNetV2WithSE\n",
    "from classification_models.ShuffleNet_SEPCONV import ShuffleNetV2WithSepConv\n",
    "from classification_models.ShuffleNet_SEPCONV_SE import ShuffleNetV2WithSepConvAndSE\n",
    "from classification_models.SqueezeNet import SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-IbUIWq8TpNs"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def run_training(model, train_loader, val_loader, num_epochs=20, start=0, lr=1e-3, optimizer=None, log_dir=\"./runs/\", save_dir=\"./checkpoints/\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    global_step = 0\n",
    "\n",
    "    for epoch in range(start, start + num_epochs):\n",
    "        model.train()\n",
    "        train_loss = train_correct = train_total = 0\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{start + num_epochs} [Train]\")\n",
    "        for images, labels in train_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size = labels.size(0)\n",
    "            train_loss += loss.item() * batch_size\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            train_correct += preds.eq(labels).sum().item()\n",
    "            train_total += batch_size\n",
    "\n",
    "            batch_acc = 100. * preds.eq(labels).sum().item() / batch_size\n",
    "            train_bar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{batch_acc:.2f}%\")\n",
    "            writer.add_scalar(\"Train/Batch_Loss\", loss.item(), global_step)\n",
    "            writer.add_scalar(\"Train/Batch_Acc\", batch_acc, global_step)\n",
    "            global_step += 1\n",
    "\n",
    "        epoch_train_loss = train_loss / train_total\n",
    "        epoch_train_acc = 100. * train_correct / train_total\n",
    "        writer.add_scalar(\"Train/Epoch_Loss\", epoch_train_loss, epoch)\n",
    "        writer.add_scalar(\"Train/Epoch_Acc\", epoch_train_acc, epoch)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = val_correct = val_total = 0\n",
    "        val_bar = tqdm(val_loader, desc=f\"Epoch {epoch}/{start + num_epochs} [Val]\")\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_bar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                batch_size = labels.size(0)\n",
    "                val_loss += loss.item() * batch_size\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                val_correct += preds.eq(labels).sum().item()\n",
    "                val_total += batch_size\n",
    "\n",
    "                batch_acc = 100. * preds.eq(labels).sum().item() / batch_size\n",
    "                val_bar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{batch_acc:.2f}%\")\n",
    "\n",
    "        epoch_val_loss = val_loss / val_total\n",
    "        epoch_val_acc = 100. * val_correct / val_total\n",
    "        writer.add_scalar(\"Val/Epoch_Loss\", epoch_val_loss, epoch)\n",
    "        writer.add_scalar(\"Val/Epoch_Acc\", epoch_val_acc, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch:2d} | Train Loss: {epoch_train_loss:.4f}, Acc: {epoch_train_acc:.2f}% | Val Loss: {epoch_val_loss:.4f}, Acc: {epoch_val_acc:.2f}%\")\n",
    "\n",
    "        # Checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': epoch_train_loss,\n",
    "            'val_loss': epoch_val_loss,\n",
    "        }, os.path.join(save_dir, f\"ckpt_epoch_{epoch:03d}.pt\"))\n",
    "\n",
    "        scheduler.step(epoch_val_loss)\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All class directories are present.\n",
      "✅ Loaded weights from C:\\Users\\PC\\Documents\\Eman\\checkpoints\\ckpt_epoch_006.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/107 [Train]: 100%|████████████████████████████████| 1846/1846 [07:13<00:00,  4.25it/s, acc=63.16%, loss=1.2349]\n",
      "Epoch 7/107 [Val]: 100%|████████████████████████████████████| 462/462 [01:47<00:00,  4.28it/s, acc=76.92%, loss=0.8564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 1.2007, Acc: 65.85% | Val Loss: 1.2487, Acc: 64.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/107 [Train]: 100%|████████████████████████████████| 1846/1846 [07:49<00:00,  3.93it/s, acc=73.68%, loss=0.8914]\n",
      "Epoch 8/107 [Val]: 100%|████████████████████████████████████| 462/462 [01:49<00:00,  4.23it/s, acc=76.92%, loss=1.1180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 1.1453, Acc: 67.32% | Val Loss: 1.2714, Acc: 63.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/107 [Train]: 100%|████████████████████████████████| 1846/1846 [07:37<00:00,  4.04it/s, acc=73.68%, loss=0.9606]\n",
      "Epoch 9/107 [Val]: 100%|████████████████████████████████████| 462/462 [01:48<00:00,  4.27it/s, acc=69.23%, loss=1.1255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 1.0880, Acc: 68.91% | Val Loss: 1.1827, Acc: 66.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:21<00:00,  4.19it/s, acc=57.89%, loss=1.2720]\n",
      "Epoch 10/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:51<00:00,  4.13it/s, acc=53.85%, loss=1.9850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 1.0525, Acc: 69.56% | Val Loss: 2.1226, Acc: 47.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:14<00:00,  4.24it/s, acc=68.42%, loss=1.5319]\n",
      "Epoch 11/107 [Val]: 100%|███████████████████████████████████| 462/462 [02:05<00:00,  3.67it/s, acc=53.85%, loss=1.9310]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 1.0145, Acc: 70.71% | Val Loss: 2.7187, Acc: 36.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:20<00:00,  4.19it/s, acc=84.21%, loss=0.5872]\n",
      "Epoch 12/107 [Val]: 100%|███████████████████████████████████| 462/462 [02:05<00:00,  3.68it/s, acc=84.62%, loss=0.8232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.9804, Acc: 71.37% | Val Loss: 1.1197, Acc: 68.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:16<00:00,  4.23it/s, acc=57.89%, loss=1.6485]\n",
      "Epoch 13/107 [Val]: 100%|███████████████████████████████████| 462/462 [02:02<00:00,  3.78it/s, acc=76.92%, loss=1.3624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.9426, Acc: 72.46% | Val Loss: 1.3764, Acc: 62.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:47<00:00,  3.95it/s, acc=78.95%, loss=0.8114]\n",
      "Epoch 14/107 [Val]: 100%|███████████████████████████████████| 462/462 [02:14<00:00,  3.42it/s, acc=38.46%, loss=1.7354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.9129, Acc: 73.22% | Val Loss: 1.7983, Acc: 49.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:39<00:00,  4.01it/s, acc=78.95%, loss=0.6849]\n",
      "Epoch 15/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:47<00:00,  4.29it/s, acc=84.62%, loss=0.7009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.8873, Acc: 73.86% | Val Loss: 1.1262, Acc: 68.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:30<00:00,  4.10it/s, acc=73.68%, loss=0.8803]\n",
      "Epoch 16/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:46<00:00,  4.33it/s, acc=46.15%, loss=1.7992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.8592, Acc: 74.60% | Val Loss: 1.5720, Acc: 56.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:14<00:00,  3.73it/s, acc=68.42%, loss=0.9802]\n",
      "Epoch 17/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:44<00:00,  4.43it/s, acc=92.31%, loss=0.4617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6980, Acc: 79.34% | Val Loss: 0.8325, Acc: 76.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:29<00:00,  3.63it/s, acc=78.95%, loss=0.9887]\n",
      "Epoch 18/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:46<00:00,  4.34it/s, acc=92.31%, loss=0.5079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.6543, Acc: 80.56% | Val Loss: 0.8244, Acc: 76.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:41<00:00,  4.00it/s, acc=94.74%, loss=0.3152]\n",
      "Epoch 19/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:49<00:00,  4.23it/s, acc=84.62%, loss=0.5214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.6399, Acc: 80.94% | Val Loss: 0.8551, Acc: 75.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:00<00:00,  3.84it/s, acc=73.68%, loss=0.7362]\n",
      "Epoch 20/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:44<00:00,  4.41it/s, acc=92.31%, loss=0.4538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.6275, Acc: 81.22% | Val Loss: 0.8060, Acc: 77.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:10<00:00,  3.76it/s, acc=73.68%, loss=0.7529]\n",
      "Epoch 21/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:47<00:00,  4.31it/s, acc=92.31%, loss=0.4312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.6169, Acc: 81.56% | Val Loss: 0.8290, Acc: 76.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:45<00:00,  3.96it/s, acc=78.95%, loss=0.9270]\n",
      "Epoch 22/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:46<00:00,  4.32it/s, acc=69.23%, loss=0.6486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.6086, Acc: 81.77% | Val Loss: 0.8314, Acc: 76.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:58<00:00,  3.85it/s, acc=73.68%, loss=0.7233]\n",
      "Epoch 23/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:45<00:00,  4.37it/s, acc=84.62%, loss=0.4729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.5957, Acc: 82.01% | Val Loss: 0.8094, Acc: 77.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:14<00:00,  3.73it/s, acc=94.74%, loss=0.2890]\n",
      "Epoch 24/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:46<00:00,  4.35it/s, acc=84.62%, loss=0.5768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5923, Acc: 82.21% | Val Loss: 0.8053, Acc: 77.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:25<00:00,  3.65it/s, acc=84.21%, loss=0.5107]\n",
      "Epoch 25/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:48<00:00,  4.25it/s, acc=92.31%, loss=0.4863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.5869, Acc: 82.42% | Val Loss: 0.8043, Acc: 77.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:49<00:00,  3.49it/s, acc=78.95%, loss=0.6435]\n",
      "Epoch 26/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:47<00:00,  4.29it/s, acc=84.62%, loss=0.7030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.5792, Acc: 82.50% | Val Loss: 0.8765, Acc: 75.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:35<00:00,  3.58it/s, acc=78.95%, loss=0.7902]\n",
      "Epoch 27/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:49<00:00,  4.22it/s, acc=76.92%, loss=0.6213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5704, Acc: 82.74% | Val Loss: 0.8105, Acc: 77.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:19<00:00,  3.69it/s, acc=78.95%, loss=0.5172]\n",
      "Epoch 28/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:48<00:00,  4.26it/s, acc=84.62%, loss=0.4322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.5624, Acc: 82.98% | Val Loss: 0.8017, Acc: 77.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:26<00:00,  3.65it/s, acc=89.47%, loss=0.3479]\n",
      "Epoch 29/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:47<00:00,  4.29it/s, acc=84.62%, loss=0.5340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.5560, Acc: 83.17% | Val Loss: 0.8169, Acc: 77.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:05<00:00,  3.80it/s, acc=84.21%, loss=0.5143]\n",
      "Epoch 30/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:47<00:00,  4.28it/s, acc=92.31%, loss=0.5157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.5556, Acc: 83.13% | Val Loss: 0.8333, Acc: 76.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:35<00:00,  4.05it/s, acc=78.95%, loss=0.5092]\n",
      "Epoch 31/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:47<00:00,  4.30it/s, acc=84.62%, loss=0.6031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.5449, Acc: 83.51% | Val Loss: 0.8167, Acc: 77.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:03<00:00,  3.82it/s, acc=89.47%, loss=0.5253]\n",
      "Epoch 32/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:44<00:00,  4.44it/s, acc=84.62%, loss=0.5750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 0.5386, Acc: 83.61% | Val Loss: 0.8561, Acc: 76.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:11<00:00,  3.75it/s, acc=94.74%, loss=0.4572]\n",
      "Epoch 33/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:47<00:00,  4.32it/s, acc=84.62%, loss=0.7505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss: 0.5182, Acc: 84.24% | Val Loss: 0.7981, Acc: 77.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:51<00:00,  3.91it/s, acc=78.95%, loss=0.6466]\n",
      "Epoch 34/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:47<00:00,  4.29it/s, acc=92.31%, loss=0.5304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss: 0.5155, Acc: 84.34% | Val Loss: 0.7905, Acc: 78.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:07<00:00,  3.79it/s, acc=94.74%, loss=0.1746]\n",
      "Epoch 35/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:49<00:00,  4.23it/s, acc=84.62%, loss=0.4518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss: 0.5154, Acc: 84.31% | Val Loss: 0.7929, Acc: 78.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:44<00:00,  3.52it/s, acc=84.21%, loss=0.4420]\n",
      "Epoch 36/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:50<00:00,  4.17it/s, acc=92.31%, loss=0.5576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss: 0.5136, Acc: 84.36% | Val Loss: 0.7974, Acc: 77.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:49<00:00,  3.49it/s, acc=78.95%, loss=0.6745]\n",
      "Epoch 37/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:50<00:00,  4.17it/s, acc=92.31%, loss=0.5509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss: 0.5133, Acc: 84.44% | Val Loss: 0.7917, Acc: 78.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:49<00:00,  3.93it/s, acc=73.68%, loss=1.0395]\n",
      "Epoch 38/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:48<00:00,  4.27it/s, acc=84.62%, loss=0.6154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss: 0.5139, Acc: 84.38% | Val Loss: 0.7967, Acc: 77.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:49<00:00,  3.93it/s, acc=78.95%, loss=0.4788]\n",
      "Epoch 39/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:48<00:00,  4.26it/s, acc=92.31%, loss=0.5756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss: 0.5093, Acc: 84.59% | Val Loss: 0.7878, Acc: 78.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:15<00:00,  3.73it/s, acc=84.21%, loss=0.5274]\n",
      "Epoch 40/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:47<00:00,  4.30it/s, acc=92.31%, loss=0.5121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss: 0.5082, Acc: 84.57% | Val Loss: 0.7995, Acc: 77.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:42<00:00,  3.54it/s, acc=94.74%, loss=0.3421]\n",
      "Epoch 41/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:46<00:00,  4.32it/s, acc=76.92%, loss=0.4641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Train Loss: 0.5064, Acc: 84.79% | Val Loss: 0.7933, Acc: 77.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/107 [Train]: 100%|███████████████████████████████| 1846/1846 [08:23<00:00,  3.67it/s, acc=68.42%, loss=0.6927]\n",
      "Epoch 42/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:59<00:00,  3.87it/s, acc=84.62%, loss=0.4930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Train Loss: 0.5069, Acc: 84.42% | Val Loss: 0.7921, Acc: 77.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/107 [Train]: 100%|███████████████████████████████| 1846/1846 [07:42<00:00,  3.99it/s, acc=94.74%, loss=0.3038]\n",
      "Epoch 43/107 [Val]: 100%|███████████████████████████████████| 462/462 [01:47<00:00,  4.29it/s, acc=76.92%, loss=0.6297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Train Loss: 0.5079, Acc: 84.78% | Val Loss: 0.7922, Acc: 78.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/107 [Train]:   6%|█▉                              | 115/1846 [00:33<08:26,  3.42it/s, acc=81.25%, loss=0.7158]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m     start \u001b[38;5;241m=\u001b[39m state_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Loaded weights from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mWEIGHTS_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m run_training(model, train_loader, val_loader, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, lr\u001b[38;5;241m=\u001b[39mlr, optimizer\u001b[38;5;241m=\u001b[39moptimizer)\n",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(model, train_loader, val_loader, num_epochs, start, lr, optimizer, log_dir, save_dir)\u001b[0m\n\u001b[0;32m     14\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_correct \u001b[38;5;241m=\u001b[39m train_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     15\u001b[0m train_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [Train]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_bar:\n\u001b[0;32m     17\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m, in \u001b[0;36mCropWeedDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     18\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 20\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, label_id\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mto_tensor(pic)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\functional.py:174\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    172\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m], pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], F_pil\u001b[38;5;241m.\u001b[39mget_image_num_channels(pic))\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdefault_float_dtype)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    check_class_dirs(CLASSIFICATION_DATASET_PATH)\n",
    "    \n",
    "    dataset = CropWeedDataset(image_dir=CLASSIFICATION_DATASET_PATH, transform=transform)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "    model = ShuffleNetV2WithSE(num_classes=NUM_CLASSES).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    #load pretrained weights if available\n",
    "    if LOAD_WEIGHTS:\n",
    "        state_dict = torch.load(WEIGHTS_PATH, map_location=device)  # or 'cuda' if using GPU\n",
    "        model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "        start = state_dict.get('epoch', -1) + 1\n",
    "        print(f\"✅ Loaded weights from {WEIGHTS_PATH}\")\n",
    "\n",
    "    run_training(model, train_loader, val_loader, num_epochs=NUM_EPOCHS, start=START_EPOCH, lr=lr, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
